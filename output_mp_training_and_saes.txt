/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/jaxtyping/__init__.py:231: UserWarning: jaxtyping version >=0.2.23 should be used with Equinox version >=0.11.1
  warnings.warn(
** Ready! **
mess3 processes: 3 instances with vocab_size=3, states=3
tom_quantum processes: 2 instances with vocab_size=4, states=3
Product space: vocab_size=432
Model: 708,144 params on cuda
⚠️ Checkpoint file not found at /workspace/outputs/checkpoints/multipartite_001/checkpoint_step_500000_final.pt. Training will start from scratch.
Training:   0%|          | 0/600000 [00:00<?, ?it/s]Training (Loss: 6.3929):   0%|          | 0/600000 [00:02<?, ?it/s]Training (Loss: 6.3626):   0%|          | 0/600000 [00:02<?, ?it/s]Training (Loss: 6.3434):   0%|          | 0/600000 [00:02<?, ?it/s]Training (Loss: 6.3254):   0%|          | 0/600000 [00:02<?, ?it/s]Training (Loss: 6.3059):   0%|          | 0/600000 [00:03<?, ?it/s]Training (Loss: 6.2961):   0%|          | 0/600000 [00:03<?, ?it/s]Training (Loss: 6.2792):   0%|          | 0/600000 [00:03<?, ?it/s]Training (Loss: 6.2730):   0%|          | 0/600000 [00:03<?, ?it/s]Training (Loss: 6.2613):   0%|          | 0/600000 [00:03<?, ?it/s]Training (Loss: 6.2520):   0%|          | 0/600000 [00:04<?, ?it/s]Training (Loss: 6.2422):   0%|          | 0/600000 [00:04<?, ?it/s]Training (Loss: 6.2333):   0%|          | 0/600000 [00:04<?, ?it/s]Training (Loss: 6.2266):   0%|          | 0/600000 [00:04<?, ?it/s]Training (Loss: 6.2181):   0%|          | 0/600000 [00:05<?, ?it/s]Training (Loss: 6.2155):   0%|          | 0/600000 [00:05<?, ?it/s]Training (Loss: 6.2039):   0%|          | 0/600000 [00:05<?, ?it/s]Training (Loss: 6.1966):   0%|          | 0/600000 [00:05<?, ?it/s]Training (Loss: 6.1921):   0%|          | 0/600000 [00:05<?, ?it/s]Training (Loss: 6.1858):   0%|          | 0/600000 [00:06<?, ?it/s]Training (Loss: 6.1765):   0%|          | 0/600000 [00:06<?, ?it/s]Training (Loss: 6.1768):   0%|          | 0/600000 [00:06<?, ?it/s]Training (Loss: 6.1730):   0%|          | 0/600000 [00:06<?, ?it/s]Training (Loss: 6.1675):   0%|          | 0/600000 [00:06<?, ?it/s]Training (Loss: 6.1626):   0%|          | 0/600000 [00:07<?, ?it/s]Training (Loss: 6.1565):   0%|          | 0/600000 [00:07<?, ?it/s]Training (Loss: 6.1524):   0%|          | 0/600000 [00:07<?, ?it/s]Training (Loss: 6.1469):   0%|          | 0/600000 [00:07<?, ?it/s]Training (Loss: 6.1495):   0%|          | 0/600000 [00:07<?, ?it/s]Training (Loss: 6.1417):   0%|          | 0/600000 [00:08<?, ?it/s]Training (Loss: 6.1401):   0%|          | 0/600000 [00:08<?, ?it/s]Training (Loss: 6.1356):   0%|          | 0/600000 [00:08<?, ?it/s]Training (Loss: 6.1341):   0%|          | 0/600000 [00:08<?, ?it/s]Training (Loss: 6.1282):   0%|          | 0/600000 [00:08<?, ?it/s]Training (Loss: 6.1280):   0%|          | 0/600000 [00:09<?, ?it/s]Training (Loss: 6.1256):   0%|          | 0/600000 [00:09<?, ?it/s]Training (Loss: 6.1231):   0%|          | 0/600000 [00:09<?, ?it/s]Training (Loss: 6.1202):   0%|          | 0/600000 [00:09<?, ?it/s]Training (Loss: 6.1145):   0%|          | 0/600000 [00:09<?, ?it/s]Training (Loss: 6.1145):   0%|          | 0/600000 [00:10<?, ?it/s]Training (Loss: 6.1115):   0%|          | 0/600000 [00:10<?, ?it/s]Training (Loss: 6.1111):   0%|          | 0/600000 [00:10<?, ?it/s]Training (Loss: 6.1097):   0%|          | 0/600000 [00:10<?, ?it/s]Training (Loss: 6.1079):   0%|          | 0/600000 [00:11<?, ?it/s]Training (Loss: 6.1038):   0%|          | 0/600000 [00:11<?, ?it/s]Training (Loss: 6.1038):   0%|          | 0/600000 [00:11<?, ?it/s]Training (Loss: 6.1014):   0%|          | 0/600000 [00:11<?, ?it/s]Training (Loss: 6.1008):   0%|          | 0/600000 [00:11<?, ?it/s]Training (Loss: 6.0983):   0%|          | 0/600000 [00:12<?, ?it/s]Training (Loss: 6.0986):   0%|          | 0/600000 [00:12<?, ?it/s]Training (Loss: 6.0971):   0%|          | 0/600000 [00:12<?, ?it/s]Training (Loss: 6.0964):   0%|          | 0/600000 [00:12<?, ?it/s]Training (Loss: 6.0919):   0%|          | 0/600000 [00:12<?, ?it/s]Training (Loss: 6.0932):   0%|          | 0/600000 [00:13<?, ?it/s]Training (Loss: 6.0909):   0%|          | 0/600000 [00:13<?, ?it/s]Training (Loss: 6.0916):   0%|          | 0/600000 [00:13<?, ?it/s]Training (Loss: 6.0898):   0%|          | 0/600000 [00:13<?, ?it/s]Training (Loss: 6.0915):   0%|          | 0/600000 [00:13<?, ?it/s]Training (Loss: 6.0884):   0%|          | 0/600000 [00:14<?, ?it/s]Training (Loss: 6.0886):   0%|          | 0/600000 [00:14<?, ?it/s]Training (Loss: 6.0861):   0%|          | 0/600000 [00:14<?, ?it/s]Training (Loss: 6.0869):   0%|          | 0/600000 [00:14<?, ?it/s]Training (Loss: 6.0850):   0%|          | 0/600000 [00:14<?, ?it/s]Training (Loss: 6.0842):   0%|          | 0/600000 [00:15<?, ?it/s]Training (Loss: 6.0842):   0%|          | 0/600000 [00:15<?, ?it/s]Training (Loss: 6.0832):   0%|          | 0/600000 [00:15<?, ?it/s]Training (Loss: 6.0835):   0%|          | 0/600000 [00:15<?, ?it/s]Training (Loss: 6.0811):   0%|          | 0/600000 [00:15<?, ?it/s]Training (Loss: 6.0806):   0%|          | 0/600000 [00:16<?, ?it/s]Training (Loss: 6.0800):   0%|          | 0/600000 [00:16<?, ?it/s]Training (Loss: 6.0831):   0%|          | 0/600000 [00:16<?, ?it/s]Training (Loss: 6.0831):   0%|          | 70/600000 [00:16<39:27:40,  4.22it/s]
Traceback (most recent call last):
  File "/root/mess3_saes/train_simplexity_3xmess3_2xtquant.py", line 244, in <module>
    generate_mp_emissions(key,n_tom_quantum, n_mess3, tom_stationaries, mess3_stationaries,
  File "/root/mess3_saes/training_and_analysis_utils.py", line 881, in generate_mp_emissions
    key, *subkeys = jax.random.split(key, 1 + n_tom_quantum + n_mess3)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/random.py", line 278, in split
    return _return_prng_keys(wrapped, _split(typed_key, num))
                                      ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/random.py", line 264, in _split
    return prng.random_split(key, shape=shape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/prng.py", line 569, in random_split
    return random_split_p.bind(keys, shape=shape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 416, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 420, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 921, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/prng.py", line 581, in random_split_impl
    base_arr = random_split_impl_base(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/prng.py", line 587, in random_split_impl_base
    return split(base_arr)
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/prng.py", line 586, in <lambda>
    split = iterated_vmap_unary(keys_ndim, lambda k: impl.split(k, shape))
                                                     ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/prng.py", line 1100, in threefry_split
    shape = tuple(unsafe_map(core.concrete_dim_or_error, shape))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 1540, in concrete_dim_or_error
    if is_dim(val):
       ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 2108, in is_dim
    return is_symbolic_dim(v) or is_constant_dim(v)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/jax/_src/core.py", line 2097, in is_symbolic_dim
    return hasattr(v, "dimension_as_value")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
