{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "import seaborn as sns\n",
    "\n",
    "from simplexity.generative_processes.builder import build_hidden_markov_model\n",
    "from simplexity.generative_processes.mixed_state_presentation import LogMixedStateTreeGenerator, MyopicEntropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_entropy_rate_monte_carlo(transition_matrices, seq_length=100000, n_sequences=10):\n",
    "    \"\"\"\n",
    "    Estimate entropy rate by sampling sequences and computing empirical entropy.\n",
    "    \"\"\"\n",
    "    transition_matrices = np.array(transition_matrices, dtype=np.float64)\n",
    "    n_tokens, n_states, _ = transition_matrices.shape\n",
    "    \n",
    "    # Find stationary distribution over hidden states\n",
    "    marginal_transitions = transition_matrices.sum(axis=0)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(marginal_transitions.T)\n",
    "    stationary_idx = np.argmax(np.isclose(eigenvalues, 1, atol=1e-6))\n",
    "    pi_states = np.real(eigenvectors[:, stationary_idx])\n",
    "    pi_states = pi_states / pi_states.sum()\n",
    "    \n",
    "    total_log_prob = 0.0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for _ in range(n_sequences):\n",
    "        # Start from stationary distribution\n",
    "        state = np.random.choice(n_states, p=pi_states)\n",
    "        belief = pi_states.copy()\n",
    "        \n",
    "        for t in range(seq_length):\n",
    "            # Sample (token, next_state) pair jointly from current state\n",
    "            # P(token, next_state | current_state)\n",
    "            joint_probs = transition_matrices[:, state, :].reshape(-1)\n",
    "            joint_probs = joint_probs / joint_probs.sum()\n",
    "            \n",
    "            joint_idx = np.random.choice(len(joint_probs), p=joint_probs)\n",
    "            token = joint_idx // n_states\n",
    "            next_state = joint_idx % n_states\n",
    "            \n",
    "            # Compute P(token | belief) - marginalize over all states and next states\n",
    "            pred_prob = 0.0\n",
    "            for s in range(n_states):\n",
    "                pred_prob += belief[s] * transition_matrices[token, s, :].sum()\n",
    "            \n",
    "            if pred_prob > 0:\n",
    "                total_log_prob += np.log(pred_prob)\n",
    "                total_steps += 1\n",
    "            \n",
    "            # Bayesian update: P(S_t | X_t = token, belief_{t-1})\n",
    "            # P(S_t = s' | token, belief) ∝ Σ_s belief[s] × P(token, s' | s)\n",
    "            new_belief = np.zeros(n_states)\n",
    "            for s_next in range(n_states):\n",
    "                for s_prev in range(n_states):\n",
    "                    new_belief[s_next] += belief[s_prev] * transition_matrices[token, s_prev, s_next]\n",
    "            \n",
    "            # Normalize\n",
    "            if new_belief.sum() > 0:\n",
    "                belief = new_belief / new_belief.sum()\n",
    "            \n",
    "            state = next_state\n",
    "    \n",
    "    entropy_rate = -total_log_prob / total_steps\n",
    "    return entropy_rate\n",
    "\n",
    "\n",
    "# entropy_rate_1 = estimate_entropy_rate_monte_carlo(h1.transition_matrices, seq_length=10000, n_sequences=5)\n",
    "# entropy_rate_2 = estimate_entropy_rate_monte_carlo(h2.transition_matrices, seq_length=10000, n_sequences=5)\n",
    "# entropy_rate_3 = estimate_entropy_rate_monte_carlo(h3.transition_matrices, seq_length=10000, n_sequences=5)\n",
    "\n",
    "# print(f\"Estimated Entropy Rate: {entropy_rate_1:.4f} bits per token\")\n",
    "# print(f\"Estimated Entropy Rate: {entropy_rate_2:.4f} bits per token\")\n",
    "# print(f\"Estimated Entropy Rate: {entropy_rate_3:.4f} bits per token\")\n",
    "# print(f\"This is the theoretical minimum cross-entropy for a predictive model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bloch_walk_entropy_mc(alpha=1, beta=np.sqrt(51), \n",
    "                                   n_sequences=10000, seq_length=1000):\n",
    "    \"\"\"\n",
    "    Estimate conditional entropy via Monte Carlo sampling.\n",
    "    Much faster than exhaustive exploration.\n",
    "    \"\"\"\n",
    "    gamma = 1 / (2 * np.sqrt(alpha**2 + beta**2))\n",
    "    \n",
    "    # Transition matrices\n",
    "    T = [\n",
    "        np.array([[1/4, 0, 2*alpha*beta*gamma**2],\n",
    "                  [0, (alpha**2 - beta**2)*gamma**2, 0],\n",
    "                  [2*alpha*beta*gamma**2, 0, 1/4]]),\n",
    "        np.array([[1/4, 0, -2*alpha*beta*gamma**2],\n",
    "                  [0, (alpha**2 - beta**2)*gamma**2, 0],\n",
    "                  [-2*alpha*beta*gamma**2, 0, 1/4]]),\n",
    "        np.array([[1/4, 2*alpha*beta*gamma**2, 0],\n",
    "                  [2*alpha*beta*gamma**2, 1/4, 0],\n",
    "                  [0, 0, (alpha**2 - beta**2)*gamma**2]]),\n",
    "        np.array([[1/4, -2*alpha*beta*gamma**2, 0],\n",
    "                  [-2*alpha*beta*gamma**2, 1/4, 0],\n",
    "                  [0, 0, (alpha**2 - beta**2)*gamma**2]])\n",
    "    ]\n",
    "    \n",
    "    right_vec = np.array([1.0, 0.0, 0.0])\n",
    "    \n",
    "    total_log_prob = 0.0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for _ in range(n_sequences):\n",
    "        # Start from stationary belief\n",
    "        belief = np.array([1.0, 0.0, 0.0])\n",
    "        \n",
    "        for _ in range(seq_length):\n",
    "            # Compute P(token | belief)\n",
    "            token_probs = np.array([belief @ T[i] @ right_vec for i in range(4)])\n",
    "            \n",
    "            # Sample token\n",
    "            token = np.random.choice(4, p=token_probs)\n",
    "            \n",
    "            # Log probability for entropy calculation\n",
    "            total_log_prob += np.log(token_probs[token])\n",
    "            total_steps += 1\n",
    "            \n",
    "            # Update belief\n",
    "            belief = (belief @ T[token]) / token_probs[token]\n",
    "    \n",
    "    # Entropy = -E[log P(X_t | X_{1:t-1})]\n",
    "    entropy = -total_log_prob / total_steps\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "# tqe1 = estimate_bloch_walk_entropy_mc(alpha=1.12, beta=5.64, n_sequences=3000, seq_length=1000)\n",
    "# tqe2 = estimate_bloch_walk_entropy_mc(alpha=0.88, beta=8.64, n_sequences=3000, seq_length=1000)\n",
    "# print(f\"Estimated Conditional Entropy: {tqe1:.4f} bits per token\")\n",
    "# print(f\"Estimated Conditional Entropy: {tqe2:.4f} bits per token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning Tom Quantum parameter space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tom Quantum scan complete: 30 parameter combinations\n",
      "   alpha  beta  conditional_entropy     gamma  alpha_sq_minus_beta_sq_term  \\\n",
      "0    0.5   3.0             1.359667  0.164399                    -0.236486   \n",
      "1    0.5   5.0             1.376302  0.099504                    -0.245050   \n",
      "2    0.5   7.0             1.384926  0.071247                    -0.247462   \n",
      "3    0.5   9.0             1.385315  0.055470                    -0.248462   \n",
      "4    0.5  11.0             1.386175  0.045408                    -0.248969   \n",
      "\n",
      "   alpha_beta_term  min_transition_prob  max_transition_prob  \\\n",
      "0         0.081081            -0.236486                 0.25   \n",
      "1         0.049505            -0.245050                 0.25   \n",
      "2         0.035533            -0.247462                 0.25   \n",
      "3         0.027692            -0.248462                 0.25   \n",
      "4         0.022680            -0.248969                 0.25   \n",
      "\n",
      "   mean_transition_prob  std_transition_prob  ...   determinant     trace  \\\n",
      "0              0.029279             0.143898  ...  1.141344e-05  0.263514   \n",
      "1              0.028328             0.142489  ...  1.531713e-06  0.254950   \n",
      "2              0.028060             0.142078  ...  4.026128e-07  0.252538   \n",
      "3              0.027949             0.141906  ...  1.479290e-07  0.251538   \n",
      "4              0.027892             0.141819  ...  6.642576e-08  0.251031   \n",
      "\n",
      "   frobenius_norm  max_diagonal  min_diagonal  upper_triangle_sum  \\\n",
      "0        0.250183          0.25      0.006757                 0.0   \n",
      "1        0.250025          0.25      0.002475                 0.0   \n",
      "2        0.250006          0.25      0.001269                 0.0   \n",
      "3        0.250002          0.25      0.000769                 0.0   \n",
      "4        0.250001          0.25      0.000515                 0.0   \n",
      "\n",
      "   lower_triangle_sum  mean_max_eigenval_per_token  \\\n",
      "0                 0.0                     0.331081   \n",
      "1                 0.0                     0.299505   \n",
      "2                 0.0                     0.285533   \n",
      "3                 0.0                     0.277692   \n",
      "4                 0.0                     0.272680   \n",
      "\n",
      "   std_max_eigenval_per_token  mean_second_eigenval_per_token  \n",
      "0                         0.0                        0.236486  \n",
      "1                         0.0                        0.245050  \n",
      "2                         0.0                        0.247462  \n",
      "3                         0.0                        0.248462  \n",
      "4                         0.0                        0.248969  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid scan for Tom Quantum parameters\n",
    "tq_alpha_values = [0.5, 0.7, 0.9, 1.0, 1.2, 1.5]\n",
    "tq_beta_values = [3.0, 5.0, 7.0, 9.0, 11.0]\n",
    "\n",
    "tq_results = []\n",
    "\n",
    "print(\"\\nScanning Tom Quantum parameter space...\")\n",
    "for alpha in tqdm(tq_alpha_values):\n",
    "    for beta in tq_beta_values:\n",
    "        try:\n",
    "            # Estimate conditional entropy\n",
    "            ce = estimate_bloch_walk_entropy_mc(\n",
    "                alpha=alpha, \n",
    "                beta=beta, \n",
    "                n_sequences=20, \n",
    "                seq_length=50\n",
    "            )\n",
    "            \n",
    "            # Build transition matrices for analysis\n",
    "            gamma = 1 / (2 * np.sqrt(alpha**2 + beta**2))\n",
    "            \n",
    "            T = [\n",
    "                np.array([[1/4, 0, 2*alpha*beta*gamma**2],\n",
    "                          [0, (alpha**2 - beta**2)*gamma**2, 0],\n",
    "                          [2*alpha*beta*gamma**2, 0, 1/4]]),\n",
    "                np.array([[1/4, 0, -2*alpha*beta*gamma**2],\n",
    "                          [0, (alpha**2 - beta**2)*gamma**2, 0],\n",
    "                          [-2*alpha*beta*gamma**2, 0, 1/4]]),\n",
    "                np.array([[1/4, 2*alpha*beta*gamma**2, 0],\n",
    "                          [2*alpha*beta*gamma**2, 1/4, 0],\n",
    "                          [0, 0, (alpha**2 - beta**2)*gamma**2]]),\n",
    "                np.array([[1/4, -2*alpha*beta*gamma**2, 0],\n",
    "                          [-2*alpha*beta*gamma**2, 1/4, 0],\n",
    "                          [0, 0, (alpha**2 - beta**2)*gamma**2]])\n",
    "            ]\n",
    "            \n",
    "            # Aggregate transition matrix metrics\n",
    "            all_probs = np.concatenate([t.flatten() for t in T])\n",
    "            \n",
    "            # Compute average transition matrix for spectral analysis\n",
    "            T_avg = np.mean(T, axis=0)\n",
    "            \n",
    "            # Eigenvalue analysis of average matrix\n",
    "            eigvals, eigvecs = np.linalg.eig(T_avg)\n",
    "            eigvals_sorted = np.sort(np.abs(eigvals))[::-1]\n",
    "            eigvals_real = np.sort(np.real(eigvals))[::-1]\n",
    "            eigvals_imag_max = np.max(np.abs(np.imag(eigvals)))\n",
    "            \n",
    "            # Singular value decomposition\n",
    "            singular_vals = np.linalg.svd(T_avg, compute_uv=False)\n",
    "            cond_number = singular_vals[0] / singular_vals[-1] if singular_vals[-1] > 1e-10 else np.inf\n",
    "            \n",
    "            # Matrix structure metrics\n",
    "            diag = np.diag(T_avg)\n",
    "            upper_tri = np.triu(T_avg, k=1).sum()\n",
    "            lower_tri = np.tril(T_avg, k=-1).sum()\n",
    "            \n",
    "            # Per-token matrix metrics\n",
    "            eigenvalues_per_token = []\n",
    "            for t_mat in T:\n",
    "                eigs = np.linalg.eigvals(t_mat)\n",
    "                eigenvalues_per_token.append(np.sort(np.abs(eigs))[::-1])\n",
    "            eigenvalues_per_token = np.array(eigenvalues_per_token)\n",
    "            \n",
    "            tq_results.append({\n",
    "                'alpha': alpha,\n",
    "                'beta': beta,\n",
    "                'conditional_entropy': ce,\n",
    "                'gamma': gamma,\n",
    "                'alpha_sq_minus_beta_sq_term': (alpha**2 - beta**2)*gamma**2,\n",
    "                'alpha_beta_term': 2*alpha*beta*gamma**2,\n",
    "                'min_transition_prob': all_probs.min(),\n",
    "                'max_transition_prob': all_probs.max(),\n",
    "                'mean_transition_prob': all_probs.mean(),\n",
    "                'std_transition_prob': all_probs.std(),\n",
    "                'nonzero_prob_count': (all_probs > 1e-10).sum(),\n",
    "                # Spectral metrics for average matrix\n",
    "                'spectral_radius': eigvals_sorted[0],\n",
    "                'largest_eigenval': eigvals_sorted[0],\n",
    "                'second_eigenval': eigvals_sorted[1] if len(eigvals_sorted) > 1 else 0.0,\n",
    "                'third_eigenval': eigvals_sorted[2] if len(eigvals_sorted) > 2 else 0.0,\n",
    "                'largest_real_eigenval': eigvals_real[0],\n",
    "                'max_imag_eigenval': eigvals_imag_max,\n",
    "                'condition_number': cond_number,\n",
    "                'determinant': np.linalg.det(T_avg),\n",
    "                'trace': diag.sum(),\n",
    "                'frobenius_norm': np.linalg.norm(T_avg, 'fro'),\n",
    "                'max_diagonal': diag.max(),\n",
    "                'min_diagonal': diag.min(),\n",
    "                'upper_triangle_sum': upper_tri,\n",
    "                'lower_triangle_sum': lower_tri,\n",
    "                # Per-token eigenvalue statistics\n",
    "                'mean_max_eigenval_per_token': eigenvalues_per_token[:, 0].mean(),\n",
    "                'std_max_eigenval_per_token': eigenvalues_per_token[:, 0].std(),\n",
    "                'mean_second_eigenval_per_token': eigenvalues_per_token[:, 1].mean(),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error for alpha={alpha}, beta={beta}: {e}\")\n",
    "            continue\n",
    "\n",
    "tq_df = pd.DataFrame(tq_results)\n",
    "tq_df.to_csv('tom_quantum_parameter_scan.csv', index=False)\n",
    "print(f\"\\nTom Quantum scan complete: {len(tq_df)} parameter combinations\")\n",
    "print(tq_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning Mess3 parameter space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:00<00:00, 44.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for a=0.1, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.1, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.2, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.3, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.4, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.5, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.6, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.7, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.4: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.8, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.05: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.1: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.15: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.2: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.25: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.35: name 'calculate_conditional_entropy' is not defined\n",
      "Error for a=0.9, x=0.4: name 'calculate_conditional_entropy' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 43.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for a=0.9, x=0.45: name 'calculate_conditional_entropy' is not defined\n",
      "\n",
      "Mess3 scan complete: 0 parameter combinations\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Grid scan for Mess3 parameters\n",
    "mess3_a_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "mess3_x_values = [0.05, 0.1, 0.15, 0.2, 0.25, 0.35, 0.4, 0.45]\n",
    "\n",
    "mess3_results = []\n",
    "\n",
    "print(\"Scanning Mess3 parameter space...\")\n",
    "for a in tqdm(mess3_a_values):\n",
    "    for x in mess3_x_values:\n",
    "        try:\n",
    "            # Build HMM\n",
    "            hmm = build_hidden_markov_model(\"mess3\", a=a, x=x)\n",
    "            \n",
    "            # Get marginal transition matrix\n",
    "            tmat = hmm.transition_matrices.sum(axis=0)\n",
    "            tmat = np.array(tmat, dtype=np.float64)\n",
    "            \n",
    "            # Calculate conditional entropy\n",
    "            ce, stationary = calculate_conditional_entropy(hmm.transition_matrices)\n",
    "            \n",
    "            # Monte Carlo estimate (faster, fewer sequences for grid scan)\n",
    "            mc_ce = estimate_entropy_rate_monte_carlo(\n",
    "                hmm.transition_matrices, \n",
    "                seq_length=50, \n",
    "                n_sequences=10\n",
    "            )\n",
    "            \n",
    "            # Eigenvalue analysis\n",
    "            eigvals, eigvecs = np.linalg.eig(tmat)\n",
    "            eigvals_sorted = np.sort(np.abs(eigvals))[::-1]\n",
    "            non_unit_eig = eigvals_sorted[1] if len(eigvals_sorted) > 1 else 0.0\n",
    "            \n",
    "            # Matrix metrics\n",
    "            diag = np.diag(tmat)\n",
    "            upper_tri = np.triu(tmat, k=1).sum()\n",
    "            lower_tri = np.tril(tmat, k=-1).sum()\n",
    "            \n",
    "            # Singular values for condition number\n",
    "            singular_vals = np.linalg.svd(tmat, compute_uv=False)\n",
    "            print(f\"{singular_vals=}\")\n",
    "            cond_number = singular_vals[0] / singular_vals[-1] if singular_vals[-1] > 1e-10 else np.inf\n",
    "            \n",
    "            # Off-diagonal variance\n",
    "            off_diag = tmat.copy()\n",
    "            np.fill_diagonal(off_diag, 0)\n",
    "            off_diag_var = np.var(off_diag[off_diag > 0]) if (off_diag > 0).any() else 0.0\n",
    "            \n",
    "            mess3_results.append({\n",
    "                'a': a,\n",
    "                'x': x,\n",
    "                'conditional_entropy': ce,\n",
    "                'mc_entropy': mc_ce,\n",
    "                'max_diagonal': diag.max(),\n",
    "                'trace': diag.sum(),\n",
    "                'upper_triangle_sum': upper_tri,\n",
    "                'lower_triangle_sum': lower_tri,\n",
    "                'non_unit_eigenvalue': non_unit_eig,\n",
    "                'frobenius_norm': np.linalg.norm(tmat, 'fro'),\n",
    "                'spectral_radius': eigvals_sorted[0],\n",
    "                'condition_number': cond_number,\n",
    "                'determinant': np.linalg.det(tmat),\n",
    "                'off_diagonal_variance': off_diag_var,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error for a={a}, x={x}: {e}\")\n",
    "            continue\n",
    "\n",
    "mess3_df = pd.DataFrame(mess3_results)\n",
    "mess3_df.to_csv('mess3_parameter_scan.csv', index=False)\n",
    "print(f\"\\nMess3 scan complete: {len(mess3_df)} parameter combinations\")\n",
    "print(mess3_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations for Tom Quantum\n",
    "print(\"\\nGenerating Tom Quantum visualizations...\")\n",
    "\n",
    "# 1. Heatmap of conditional entropy vs (alpha, beta)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "tq_ce_matrix = tq_df.pivot(index='beta', columns='alpha', values='conditional_entropy')\n",
    "\n",
    "sns.heatmap(tq_ce_matrix, annot=True, fmt='.3f', cmap='plasma', ax=ax)\n",
    "ax.set_title('Tom Quantum Conditional Entropy')\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('beta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tom_quantum_entropy_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Scatter plots: CE vs each metric\n",
    "tq_metric_cols = [col for col in tq_df.columns if col not in ['alpha', 'beta', 'conditional_entropy']]\n",
    "\n",
    "n_metrics = len(tq_metric_cols)\n",
    "n_cols = 3\n",
    "n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(tq_metric_cols):\n",
    "    ax = axes[idx]\n",
    "    scatter = ax.scatter(tq_df[metric], tq_df['conditional_entropy'], \n",
    "                        c=tq_df['alpha'], cmap='coolwarm', s=50, alpha=0.7)\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_ylabel('Conditional Entropy')\n",
    "    ax.set_title(f'CE vs {metric}')\n",
    "    plt.colorbar(scatter, ax=ax, label='alpha')\n",
    "    \n",
    "    # Add correlation\n",
    "    corr = np.corrcoef(tq_df[metric], tq_df['conditional_entropy'])[0, 1]\n",
    "    ax.text(0.05, 0.95, f'r = {corr:.3f}', transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(tq_metric_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tom_quantum_ce_vs_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Tom Quantum visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations for Mess3\n",
    "print(\"\\nGenerating Mess3 visualizations...\")\n",
    "\n",
    "# 1. Heatmap of conditional entropy vs (a, x)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Reshape for heatmap\n",
    "ce_matrix = mess3_df.pivot(index='x', columns='a', values='conditional_entropy')\n",
    "mc_matrix = mess3_df.pivot(index='x', columns='a', values='mc_entropy')\n",
    "\n",
    "sns.heatmap(ce_matrix, annot=True, fmt='.3f', cmap='viridis', ax=axes[0])\n",
    "axes[0].set_title('Mess3 Conditional Entropy (Analytical)')\n",
    "axes[0].set_xlabel('a (asymmetry)')\n",
    "axes[0].set_ylabel('x (noise)')\n",
    "\n",
    "sns.heatmap(mc_matrix, annot=True, fmt='.3f', cmap='viridis', ax=axes[1])\n",
    "axes[1].set_title('Mess3 Conditional Entropy (Monte Carlo)')\n",
    "axes[1].set_xlabel('a (asymmetry)')\n",
    "axes[1].set_ylabel('x (noise)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mess3_entropy_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Scatter plots: CE vs each matrix metric\n",
    "metric_cols = [col for col in mess3_df.columns if col not in ['a', 'x', 'conditional_entropy', 'mc_entropy']]\n",
    "\n",
    "n_metrics = len(metric_cols)\n",
    "n_cols = 3\n",
    "n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metric_cols):\n",
    "    ax = axes[idx]\n",
    "    scatter = ax.scatter(mess3_df[metric], mess3_df['conditional_entropy'], \n",
    "                        c=mess3_df['a'], cmap='coolwarm', s=50, alpha=0.7)\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_ylabel('Conditional Entropy')\n",
    "    ax.set_title(f'CE vs {metric}')\n",
    "    plt.colorbar(scatter, ax=ax, label='a (asymmetry)')\n",
    "    \n",
    "    # Add correlation\n",
    "    corr = np.corrcoef(mess3_df[metric], mess3_df['conditional_entropy'])[0, 1]\n",
    "    ax.text(0.05, 0.95, f'r = {corr:.3f}', transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(metric_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mess3_ce_vs_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Mess3 visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and correlation analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MESS3 SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nConditional Entropy range: [{mess3_df['conditional_entropy'].min():.4f}, {mess3_df['conditional_entropy'].max():.4f}]\")\n",
    "print(f\"Mean CE: {mess3_df['conditional_entropy'].mean():.4f}\")\n",
    "print(f\"Std CE: {mess3_df['conditional_entropy'].std():.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 correlations with CE:\")\n",
    "correlations = {}\n",
    "for col in mess3_df.columns:\n",
    "    if col not in ['a', 'x', 'conditional_entropy', 'mc_entropy']:\n",
    "        corr = np.corrcoef(mess3_df[col], mess3_df['conditional_entropy'])[0, 1]\n",
    "        correlations[col] = corr\n",
    "\n",
    "for metric, corr in sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:5]:\n",
    "    print(f\"  {metric:30s}: r = {corr:7.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOM QUANTUM SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nConditional Entropy range: [{tq_df['conditional_entropy'].min():.4f}, {tq_df['conditional_entropy'].max():.4f}]\")\n",
    "print(f\"Mean CE: {tq_df['conditional_entropy'].mean():.4f}\")\n",
    "print(f\"Std CE: {tq_df['conditional_entropy'].std():.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 correlations with CE:\")\n",
    "tq_correlations = {}\n",
    "for col in tq_df.columns:\n",
    "    if col not in ['alpha', 'beta', 'conditional_entropy']:\n",
    "        corr = np.corrcoef(tq_df[col], tq_df['conditional_entropy'])[0, 1]\n",
    "        tq_correlations[col] = corr\n",
    "\n",
    "for metric, corr in sorted(tq_correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:5]:\n",
    "    print(f\"  {metric:30s}: r = {corr:7.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(\"  - mess3_parameter_scan.csv\")\n",
    "print(\"  - tom_quantum_parameter_scan.csv\")\n",
    "print(\"  - mess3_entropy_heatmap.png\")\n",
    "print(\"  - mess3_ce_vs_metrics.png\")\n",
    "print(\"  - tom_quantum_entropy_heatmap.png\")\n",
    "print(\"  - tom_quantum_ce_vs_metrics.png\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simplex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
