# -*- coding: utf-8 -*-
"""Simplexity_3xMess3_2xTQuant

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TdFJvobna_lbkUA-I9TbcIuuFw_ZdgGK
"""

#%%

# Commented out IPython magic to ensure Python compatibility.
# Cell 1: Installation (skip if already installed)
# %pip -q install --upgrade pip wheel setuptools
# %pip -q install "einops>=0.7.0" "jaxtyping>=0.2.28" "beartype>=0.14" better_abc
# %pip -q install --no-deps "transformer-lens>=2.16.1"
# %pip -q install "git+https://github.com/Astera-org/simplexity.git@MATS_2025_app"

# Cell 2: Setup - Product of tom_quantum and mess3
import os, sys
os.environ["JAX_PLATFORMS"] = "cpu"
os.environ["JAX_PLATFORM_NAME"] = "cpu"
import argparse
import torch
import torch.nn.functional as F
import numpy as np
import jax
import jax.numpy as jnp
from transformer_lens import HookedTransformer, HookedTransformerConfig
from simplexity.generative_processes.builder import build_hidden_markov_model, build_generalized_hidden_markov_model
from simplexity.generative_processes.torch_generator import generate_data_batch

from tqdm import tqdm
import pickle
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.decomposition import PCA
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px # Import plotly.express for categorical colors
import plotly.io as pio
from math import comb
from itertools import combinations
from training_and_analysis_utils import generate_mp_emissions

print("** Ready! **")

#%%
# ============= Argument parsing ============= #
################################################
def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train Transformer on product of Mess3 and Tom Quantum processes", allow_abbrev=False)
    parser.add_argument("--n_mess3", type=int, default=3, help="Number of mess3 processes")
    parser.add_argument("--n_tom_quantum", type=int, default=2, help="Number of tom_quantum processes")
    #parser.add_argument("--checkpoint_path", type=str, default="/workspace/checkpoints/multipartite_001", help="Directory to save checkpoints")
    #parser.add_argument("--fig_out_dir", type=str, default="/workspace/output/multipartite_001", help="Directory to save matplotlib figures")
    parser.add_argument("--checkpoint_path", type=str, default="outputs/checkpoints/multipartite_001", help="Directory to save checkpoints")
    parser.add_argument("--fig_out_dir", type=str, default="outputs/reports/multipartite_001", help="Directory to save matplotlib figures")
    parser.add_argument("--num_steps", type=int, default=500000, help="Training steps")
    parser.add_argument("--d_model", type=int, default=128)
    parser.add_argument("--n_heads", type=int, default=4)
    parser.add_argument("--n_layers", type=int, default=3)
    parser.add_argument("--n_ctx", type=int, default=16)
    parser.add_argument("--act_fn", type=str, default="relu")
    parser.add_argument("--d_head", type=int, default=32)
    parser.add_argument("--device", type=str, default="auto", choices=["auto", "cpu", "cuda"], help="Device preference")
    parser.add_argument("--batch_size", type=int, default=2048)
    parser.add_argument("--pct_var_explained", type=float, default=0.99, help="Percentage of variance explained")
    args, _ = parser.parse_known_args()
    return args

args = _parse_args()

if os.path.isfile(args.fig_out_dir):
    raise ValueError(f"fig_out_dir points to a file: {args.fig_out_dir}")
os.makedirs(args.fig_out_dir, exist_ok=True)


#%%
# #%%
# print(f"{mess3_vocab_size=}, {tom_quantum_vocab_size=}")
# print(f"{n_mess3=}, {n_tom_quantum=}")
# all_tokens = []
# for mi1 in range(mess3_vocab_size):
#     for mi2 in range(mess3_vocab_size):
#         for mi3 in range(mess3_vocab_size):
#             for ti1 in range(tom_quantum_vocab_size):
#                 for ti2 in range(tom_quantum_vocab_size):
#                     tok = (mi1 * mess3_vocab_size**(0) + 
#                            mi2 * mess3_vocab_size**(1) + 
#                            mi3 * mess3_vocab_size**(2) + 
#                            ti1 *mess3_vocab_size**3 * tom_quantum_vocab_size**(0) + 
#                            ti2 *mess3_vocab_size**3 * tom_quantum_vocab_size**(1))
#                     print(f"{mi1=}, {mi2=}, {mi3=}, {ti1=}, {ti2=}, token = {tok}")
#                     all_tokens.append(tok)

# print(f"{len(all_tokens)=}")
# print(sorted(all_tokens))



  #%%
# ==== Create Generator Processes ============= #
#################################################

# Define the number of processes for each type (from args)
n_mess3 = args.n_mess3
n_tom_quantum = args.n_tom_quantum
checkpoint_path = args.checkpoint_path

# Ensure checkpoint_path exists
os.makedirs(checkpoint_path, exist_ok=True)

# Create multiple instances of each process
m3_x = [round(x, 3) for x in np.linspace(0.1, 0.4, n_mess3)]
m3_a = [round(x, 3) for x in np.linspace(0.2, 0.8, n_mess3)]
m3_a[:-1] = m3_a[1:]
m3_a[n_mess3-1] = 0.2
mess3_processes = [build_hidden_markov_model(f"mess3", x=0.12, a=0.55),
                   build_hidden_markov_model(f"mess3", x=0.14, a=0.7),
                   build_hidden_markov_model(f"mess3", x=0.18, a=0.75)]
# Figure out what the ranges are for alpha and beta that are acceptable. Found this in
# simplexity/simplexity/generative_processes/transition_matrices.py:
# def tom_quantum(alpha: float, beta: float) -> jax.Array:
#     """Creates a transition matrix for the Tom Quantum Process."""
#     gamma2 = 1 / (4 * (alpha**2 + beta**2))
#     common_diag = 1 / 4
#     middle_diag = (alpha**2 - beta**2) * gamma2
#     off_diag = 2 * alpha * beta * gamma2
#
#     transition_matrices = jnp.array(
#         [
#             [
#                 [common_diag, 0, off_diag],
#                 [0, middle_diag, 0],
#                 [off_diag, 0, common_diag],
#             ],
#             [
#                 [common_diag, 0, -off_diag],
#                 [0, middle_diag, 0],
#                 [-off_diag, 0, common_diag],
#             ],
#             [
#                 [common_diag, off_diag, 0],
#                 [off_diag, common_diag, 0],
#                 [0, 0, middle_diag],
#             ],
#             [
#                 [common_diag, -off_diag, 0],
#                 [-off_diag, common_diag, 0],
#                 [0, 0, middle_diag],
#             ],
#         ]
#     )
#     return transition_matrices
tom_quantum_processes = [build_generalized_hidden_markov_model(f"tom_quantum", alpha=1.12, beta=5.64),
                         build_generalized_hidden_markov_model(f"tom_quantum", alpha=0.88, beta=8.64)]

# Assuming all instances of a type have the same vocab size and states
# Handle the case where n_mess3 or n_tom_quantum is 0
mess3_vocab_size = mess3_processes[0].vocab_size if n_mess3 > 0 else 1
mess3_num_states = mess3_processes[0].num_states if n_mess3 > 0 else 1
tom_quantum_vocab_size = tom_quantum_processes[0].vocab_size if n_tom_quantum > 0 else 1
tom_quantum_num_states = tom_quantum_processes[0].num_states if n_tom_quantum > 0 else 1

product_vocab_size = (tom_quantum_vocab_size ** n_tom_quantum) * (mess3_vocab_size ** n_mess3)

print(f"mess3 processes: {n_mess3} instances with vocab_size={mess3_vocab_size}, states={mess3_num_states}")
print(f"tom_quantum processes: {n_tom_quantum} instances with vocab_size={tom_quantum_vocab_size}, states={tom_quantum_num_states}")



#%%
# ==== Create Model ==== #
##########################

# Product space has vocab_size =  n_tom_quantum * tom_quantum_vocab_size * n_mess3 * mess3_vocab_size
# This calculation needs to be adjusted based on how the product space is formed.
# Assuming the product space is formed by combining outputs from one instance of each type
# The total vocab size will be the product of the vocab sizes of all individual processes.
# If we are combining one output from *each* mess3 and *each* tom_quantum process:


print(f"Product space: vocab_size={product_vocab_size}")


# ---- 1) Enable fast paths (do this once, BEFORE model init) ----
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
torch.set_float32_matmul_precision("high")

torch.backends.cuda.enable_flash_sdp(True)
torch.backends.cuda.enable_mem_efficient_sdp(True)
torch.backends.cuda.enable_math_sdp(False)


scaler_enabled = True  # bfloat16 autocast; set False to disable


# Create TransformerLens model for product space
if args.device == "auto":
    device = "cuda" if torch.cuda.is_available() else "cpu"
else:
    device = args.device
cfg = HookedTransformerConfig(
    d_model=args.d_model,
    n_heads=args.n_heads,
    n_layers=args.n_layers,
    n_ctx=args.n_ctx,
    d_vocab=product_vocab_size,  # Adjusted vocab size
    act_fn=args.act_fn,
    device=device,
    d_head=args.d_head
)
model = HookedTransformer(cfg)
print(f"Model: {sum(p.numel() for p in model.parameters()):,} params on {device}")

# # Load model weights from checkpoint
# checkpoint_path = os.path.join(args.checkpoint_path, "checkpoint_step_500000_final.pt")
# if os.path.exists(checkpoint_path):
#     print(f"Loading model and optimizer state from {checkpoint_path}")
#     checkpoint = torch.load(checkpoint_path, map_location=device)
#     model.load_state_dict(checkpoint['model_state_dict'])
#     # If you want to restore optimizer and losses, you can do so here:
#     # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
#     # losses = checkpoint['losses']
#     print("✅ Model (and optionally optimizer/losses) loaded from checkpoint.")
# else:
#     print(f"⚠️ Checkpoint file not found at {checkpoint_path}. Training will start from scratch.")



#%%
# ==== Train Model ===== #
##########################
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, fused=True)
#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
losses = []
batch_size, seq_len = args.batch_size, cfg.n_ctx
key = jax.random.PRNGKey(42)

# Get stationary distributions for all processes
tom_stationaries = [p.initial_state for p in tom_quantum_processes]
mess3_stationaries = [p.initial_state for p in mess3_processes]

# List to store cumulative variance data and activations
cumulative_variance_data = []
all_layer_activations = {} # Dictionary to store activations for each layer

# Create the tqdm progress bar object
num_steps = args.num_steps
miniters = 30_000 if num_steps > 30_000 else num_steps
progress_bar = tqdm(range(num_steps), desc="Training", miniters=miniters, disable=not sys.stderr.isatty())

checkpoints_to_save = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 12500, 15000, 17500, 20000, 23000, 24000, 25000,
                       30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, 85000, 90000, 95000, 100000,
                       125000, 150000, 175000, 200000, 230000, 240000, 250000, 300000, 350000, 400000, 450000, 500000, 550000, 600000]
for step in progress_bar:
    key, tom_inputs_list, mess3_inputs_list, tokens = \
        generate_mp_emissions(key,n_tom_quantum, n_mess3, tom_stationaries, mess3_stationaries,
                              batch_size, seq_len, tom_quantum_processes, mess3_processes,
                              tom_quantum_vocab_size, mess3_vocab_size, product_vocab_size, device)

    # Train step
    with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=scaler_enabled):
        loss = model(tokens, return_type="loss")
    #loss = model(tokens, return_type="loss")
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    losses.append(loss.item())

    # Save cumulative variance and activations every 100 steps
    if (step + 1) % 5000 == 0:
        with torch.no_grad():
            toks_small = tokens[:128]  # or random index subset
            _, cache = model.run_with_cache(toks_small, return_type=None)

        # Store activations for each layer
        current_step_activations = {}
        for layer in range(cfg.n_layers):
            hook_name = f'blocks.{layer}.hook_resid_post'
            if hook_name in cache:
                current_step_activations[f'layer_{layer}'] = cache[hook_name].cpu().numpy()
            else:
                print(f"Warning: Hook '{hook_name}' not found in cache.")

        # Append activations for this step to the main dictionary
        all_layer_activations[step + 1] = current_step_activations


        # Perform PCA and calculate cumulative variance for the last layer
        if f'layer_{cfg.n_layers - 1}' in current_step_activations:
            last_layer_activations = current_step_activations[f'layer_{cfg.n_layers - 1}']
            # Flatten for PCA
            activations_flat = last_layer_activations.reshape(-1, last_layer_activations.shape[-1])

            # Perform PCA
            pca = PCA() # No n_components here to get all components
            pca.fit(activations_flat)

            # Calculate cumulative explained variance
            cumulative_variance = np.cumsum(pca.explained_variance_ratio_)

            # Store the data
            cumulative_variance_data.append({'step': step + 1, 'cumulative_variance': cumulative_variance})
        else:
             print(f"Warning: Activations for layer {cfg.n_layers - 1} not found in cache for PCA.")

    # Save a checkpoint every 5% of the way through training (but not the final checkpoint here)
    if (step + 1) in checkpoints_to_save:
        checkpoint = {
            'step': step + 1,
            'model_state_dict': model.state_dict(),
            #'optimizer_state_dict': optimizer.state_dict(),
            'losses': losses,
        }
        checkpoint_filename = os.path.join(checkpoint_path, f'checkpoint_step_{step + 1}.pt')
        torch.save(checkpoint, checkpoint_filename)
        print(f"Checkpoint saved at step {step + 1} to {checkpoint_filename}")
        progress_bar.set_description(f"Training (Loss: {loss.item():.4f})", refresh=False)
    #if (step + 1) % miniters == 0:
    #    progress_bar.set_description(f"Training (Loss: {loss.item():.4f})", refresh=False)


# Save the final checkpoint after training is complete
final_checkpoint = {
    'step': num_steps,
    'model_state_dict': model.state_dict(),
    #'optimizer_state_dict': optimizer.state_dict(),
    'losses': losses,
}
final_checkpoint_filename = os.path.join(checkpoint_path, f'checkpoint_step_{num_steps}_final.pt')
torch.save(final_checkpoint, final_checkpoint_filename)
print(f"Final checkpoint saved at step {num_steps} to {final_checkpoint_filename}")

#%%
# ==== Save Pickles ===== #
###########################

print(f"\nFinal loss: {losses[-1]:.4f} (started at {losses[0]:.4f})")

# Save the cumulative variance data to a file
cve_pickle_filename = os.path.join(checkpoint_path, f'cumulative_variance_data.pkl')
with open(cve_pickle_filename, 'wb') as f:
    pickle.dump(cumulative_variance_data, f)

# Save the layer activations data to a file
all_layer_activations_pickle_filename = os.path.join(checkpoint_path, f'all_layer_activations.pkl')
with open(all_layer_activations_pickle_filename, 'wb') as f:
    pickle.dump(all_layer_activations, f)

print("Cumulative variance data saved to cumulative_variance_data.pkl")
print("All layer activations data saved to all_layer_activations.pkl")


#%%
final_checkpoint_filename = os.path.join(checkpoint_path, f'checkpoint_step_{num_steps}_final.pt')
ckpt = torch.load(final_checkpoint_filename)

# Define model and optimizer before loading their states
cfg = HookedTransformerConfig(
    d_model=args.d_model,
    n_heads=args.n_heads,
    n_layers=args.n_layers,
    n_ctx=args.n_ctx,
    d_head=args.d_head,
    act_fn=args.act_fn,
    d_vocab=product_vocab_size,  # You may want to set this if needed
)
model = HookedTransformer(cfg)
#optimizer = torch.optim.Adam(model.parameters())

model.load_state_dict(ckpt['model_state_dict'])
#optimizer.load_state_dict(ckpt['optimizer_state_dict'])
losses = ckpt['losses']
#print(f"Loaded model and optimizer state from {final_checkpoint_filename}")
print(f"Loaded model state from {final_checkpoint_filename}")
print(f"Loaded losses from {final_checkpoint_filename}")

#%%
# ==== Visualize Loss ==== #
############################

os.makedirs(args.fig_out_dir, exist_ok=True)

plt.plot(losses)
plt.xlabel('Step')
plt.ylabel('Loss')
plt.title('Training Loss on Product Space (multiple processes)')
plt.tight_layout()
plt.savefig(os.path.join(args.fig_out_dir, 'loss.png'))
plt.close()

# Visualization of loss
# Calculate moving average
window_size = 50 # You can adjust the window size
moving_average = np.convolve(losses, np.ones(window_size)/window_size, mode='valid')

# Plot original loss with transparency
plt.figure()
plt.plot(losses, alpha=0.5, label='Original Loss') 
# Plot moving average
plt.plot(range(window_size - 1, len(losses)), moving_average,
         label=f'Moving Average (window={window_size})') 

plt.xlabel('Step')
plt.ylabel('Loss')
plt.title('Training Loss on Product Space (multiple processes)')

# Calculate ylim based on percentiles
ylim_min = 0.9999 * np.min(losses)
ylim_max = ylim_min + 0.25 * (np.max(losses) - ylim_min)
plt.ylim([ylim_min, ylim_max])
#plt.xlim(0,80000)
#plt.yscale('log')  # Set y-axis to logarithmic scale
# Add vertical dotted lines
plt.axvline(x=5000, color='gray', linestyle=':', label='6 dims')
plt.axvline(x=10000, color='gray', linestyle=':', label='10 dims')
plt.legend()
os.makedirs(args.fig_out_dir, exist_ok=True)
plt.tight_layout()
plt.savefig(os.path.join(args.fig_out_dir, 'loss_moving_average.png'))
plt.close()
print("Saved loss moving average plot to ", os.path.join(args.fig_out_dir, 'loss_moving_average.png'))

#%%
# ==== Plot Cumulative Variance ==== #
######################################

try:
    with open(os.path.join(checkpoint_path, f'cumulative_variance_data.pkl'), 'rb') as f:
        cumulative_variance_data = pickle.load(f)
except FileNotFoundError:
    print(f"Error: {os.path.join(checkpoint_path, f'cumulative_variance_data.pkl')} not found. Please run the training cell first.")
    cumulative_variance_data = []

if cumulative_variance_data:
    # List of target explained variance percentages
    pct_var_list = [0.90, 0.95, 0.99]
    colors = ['tab:blue', 'tab:orange', 'tab:green']
    labels = ['90%', '95%', '99%']
    dims_to_var_dict = {pct: [] for pct in pct_var_list}
    steps = []

    for item in cumulative_variance_data:
        step = item['step']
        cumulative_variance = item['cumulative_variance']
        steps.append(step)
        for pct in pct_var_list:
            # Find the number of components to reach pct cumulative variance
            components_needed = np.argmax(cumulative_variance >= pct) + 1
            dims_to_var_dict[pct].append(components_needed)

    plt.figure(figsize=(10, 6))
    for pct, color, label in zip(pct_var_list, colors, labels):
        plt.plot(steps, dims_to_var_dict[pct], marker='o', linestyle='-', color=color, label=f'{label} Variance')

    plt.xlabel('Training Step')
    plt.ylabel('Number of Components')
    plt.title('Dimensionality to Explain 90%, 95%, 99% Variance Over Training Time')
    plt.grid(True)
    plt.legend()

    # Force y-axis ticks to be at integer values, but not necessarily every integer labeled
    import matplotlib.ticker as mticker
    ax = plt.gca()
    # Set major ticks to integer values, but let matplotlib choose a reasonable step
    ax.yaxis.set_major_locator(mticker.MaxNLocator(integer=True, prune='both'))

    os.makedirs(args.fig_out_dir, exist_ok=True)
    plt.tight_layout()
    plt.savefig(os.path.join(args.fig_out_dir, f'dims_to_90_95_99_variance_over_time.png'))
    plt.close()
else:
    print("No cumulative variance data to plot.")
print("Saved cumulative variance plot to ", os.path.join(args.fig_out_dir, f'dims_to_90_95_99_variance_over_time.png'))



#%%
# ==== Plot Cumulative Variance by Components Over Steps ==== #
################################################################
try:
    with open(os.path.join(checkpoint_path, f'cumulative_variance_data.pkl'), 'rb') as f:
        cumulative_variance_data = pickle.load(f)
except FileNotFoundError:
    print(f"Error: {os.path.join(checkpoint_path, f'cumulative_variance_data.pkl')} not found. Please run the training cell first.")
    cumulative_variance_data = []

if cumulative_variance_data:
    plt.figure(figsize=(10, 6))

    # Get steps for colormap mapping
    steps = [item['step'] for item in cumulative_variance_data]
    min_step = min(steps)
    max_step = max(steps)

    # Define a colormap
    colormap = cm.turbo # You can choose a different colormap

    # Plot cumulative variance by number of components for each step
    for item in cumulative_variance_data:
        step = item['step']
        cumulative_variance = item['cumulative_variance']
        num_components = len(cumulative_variance)

        # Map step to color
        color = colormap((step - min_step) / (max_step - min_step))

        plt.plot(range(1, num_components + 1), cumulative_variance, linestyle='-', color=color, label=f'Step {step}',alpha=0.5,lw=5)

    plt.xlabel('Number of Components')
    plt.ylabel('Cumulative Explained Variance Ratio')
    plt.title('Cumulative Explained Variance by Number of PCA Components Over Training Steps')
    # Add a colorbar to show the mapping of color to step
    sm = cm.ScalarMappable(cmap=colormap, norm=plt.Normalize(vmin=min_step, vmax=max_step))
    sm.set_array([]) # Needed for the colorbar to work
    cbar = plt.colorbar(sm, ax=plt.gca()) # Explicitly provide the current axes
    cbar.set_label('Training Step')

    plt.grid(True)
    plt.xlim([1,20])
    os.makedirs(args.fig_out_dir, exist_ok=True)
    plt.tight_layout()
    plt.savefig(os.path.join(args.fig_out_dir, 'cumvar_by_components_over_steps.png'))
    plt.close()
else:
    print("No cumulative variance data to plot.")
print("Saved cumulative variance plot to ", os.path.join(args.fig_out_dir, f'cumvar_by_components_over_steps.png'))


#%%

# #%%
# # Create a small batch to demonstrate factored and producted outputs
# batch_size_example = 5
# seq_len_example = 10
# key, key1, key2 = jax.random.split(jax.random.PRNGKey(0), 3) # Use a fixed key for reproducibility

# # Generate from tom_quantum
# tom_states_example = jnp.repeat(tom_stationary[None, :], batch_size_example, axis=0)
# _, tom_inputs_example, _ = generate_data_batch(tom_states_example, tom_quantum, batch_size_example, seq_len_example, key1)

# # Generate from mess3
# mess3_states_example = jnp.repeat(mess3_stationary[None, :], batch_size_example, axis=0)
# _, mess3_inputs_example, _ = generate_data_batch(mess3_states_example, mess3, batch_size_example, seq_len_example, key2)

# # Convert to numpy arrays
# if isinstance(tom_inputs_example, torch.Tensor):
#     tom_arr_example = tom_inputs_example.cpu().numpy()
#     mess3_arr_example = mess3_inputs_example.cpu().numpy()
# else:
#     tom_arr_example = np.array(tom_inputs_example)
#     mess3_arr_example = np.array(mess3_inputs_example)


# # Combine into product space: token = tom * 3 + mess3
# product_tokens_example = tom_arr_example * mess3.vocab_size + mess3_arr_example

# print("Example of Factored Outputs (Tom Quantum):")
# print(tom_arr_example)

# print("\nExample of Factored Outputs (Mess3):")
# print(mess3_arr_example)

# print("\nExample of Producted Outputs (Combined Tokens):")
# print(product_tokens_example)



# #%%


# # Perform PCA on the final layer activations (3 components for 3D)
# pca = PCA(n_components=.99)
# pca_coords = pca.fit_transform(activations_flat['layer_0'])

# # Calculate cumulative explained variance
# cumulative_variance = np.cumsum(pca.explained_variance_ratio_)

# # Plot cumulative explained variance
# plt.figure(figsize=(8, 5))
# plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')
# plt.title('Cumulative Explained Variance by Number of PCA Components')
# plt.xlabel('Number of Components')
# plt.ylabel('Cumulative Explained Variance Ratio')
# plt.grid(True)
# plt.show()

# # Display a sample of the generated tokens
# print("Example of generated tokens:")
# print(tokens[0, :]) # Display the first sequence in the batch



# # Display a sample of the individual components (tom_quantum and mess3)
# print("\nExample of individual components:")
# print("Tom Quantum component:", tom_inputs[0, :])
# print("Mess3 component:", mess3_inputs[0, :])
